#!/usr/bin/env python3
"""
OpenSearch ML Commons í”ŒëŸ¬ê·¸ì¸ í…ŒìŠ¤íŠ¸
====================================

ML Commons í”ŒëŸ¬ê·¸ì¸ì˜ ì£¼ìš” ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. K-Means í´ëŸ¬ìŠ¤í„°ë§
2. RCF (Random Cut Forest) ì´ìƒ íƒì§€
3. ì™¸ë¶€ ëª¨ë¸ í†µí•©
4. ëª¨ë¸ ê´€ë¦¬ ë° ì˜ˆì¸¡

ì‘ì„±ì: KCB IT AI ì¶”ì§„ë‹¨
ë‚ ì§œ: 2025-08-12
"""

import json
import time
import numpy as np
from opensearchpy import OpenSearch
from opensearchpy.exceptions import RequestError
import warnings
warnings.filterwarnings('ignore')

class MLCommonsPluginTester:
    def __init__(self):
        """OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.client = OpenSearch(
            hosts=[{'host': 'localhost', 'port': 9200}],
            http_auth=('admin', 'Kcb2025opSLabAi9'),
            use_ssl=True,
            verify_certs=False,
            ssl_show_warn=False
        )
        print("ğŸ¤– ML Commons í”ŒëŸ¬ê·¸ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
    
    def check_ml_plugin_status(self):
        """ML Commons í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸"""
        print("\nğŸ“‹ 1. ML Commons í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸")
        print("-" * 30)
        
        try:
            # í”ŒëŸ¬ê·¸ì¸ ëª©ë¡ í™•ì¸
            response = self.client.cat.plugins(format='json', v=True)
            ml_plugins = [p for p in response if 'ml' in p['component'].lower()]
            
            if ml_plugins:
                print("âœ… ML Commons í”ŒëŸ¬ê·¸ì¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤:")
                for plugin in ml_plugins:
                    print(f"   - {plugin['component']} v{plugin['version']}")
            else:
                print("âŒ ML Commons í”ŒëŸ¬ê·¸ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ML ë…¸ë“œ ì„¤ì • í™•ì¸
            stats = self.client.nodes.stats()
            ml_enabled_nodes = 0
            for node_id, node_info in stats['nodes'].items():
                if 'plugins' in node_info and any('ml' in str(p).lower() for p in node_info.get('plugins', [])):
                    ml_enabled_nodes += 1
            
            print(f"ğŸ“Š ML í™œì„±í™” ë…¸ë“œ ìˆ˜: {ml_enabled_nodes}")
            return True
            
        except Exception as e:
            print(f"âŒ í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def setup_sample_data(self):
        """ML í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        print("\nğŸ“Š 2. ML í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
        print("-" * 30)
        
        try:
            # ê³ ê° í–‰ë™ ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±
            customer_mapping = {
                "mappings": {
                    "properties": {
                        "customer_id": {"type": "keyword"},
                        "age": {"type": "integer"},
                        "income": {"type": "float"},
                        "credit_score": {"type": "integer"},
                        "transaction_count": {"type": "integer"},
                        "avg_transaction_amount": {"type": "float"},
                        "account_balance": {"type": "float"},
                        "loan_amount": {"type": "float"},
                        "timestamp": {"type": "date"}
                    }
                }
            }
            
            index_name = "ml-customer-data"
            if self.client.indices.exists(index=index_name):
                self.client.indices.delete(index=index_name)
            
            self.client.indices.create(index=index_name, body=customer_mapping)
            print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ")
            
            # ìƒ˜í”Œ ê³ ê° ë°ì´í„° ìƒì„± (200ëª…)
            np.random.seed(42)
            customers = []
            
            for i in range(200):
                # 3ê°œ ê³ ê° ê·¸ë£¹ ì‹œë®¬ë ˆì´ì…˜
                group = np.random.choice([0, 1, 2], p=[0.5, 0.3, 0.2])
                
                if group == 0:  # ì¼ë°˜ ê³ ê°
                    age = np.random.normal(35, 10)
                    income = np.random.normal(50000, 15000)
                    credit_score = np.random.normal(650, 50)
                elif group == 1:  # ê³ ì†Œë“ ê³ ê°
                    age = np.random.normal(45, 8)
                    income = np.random.normal(100000, 20000)
                    credit_score = np.random.normal(750, 30)
                else:  # ì‹ ìš© ìœ„í—˜ ê³ ê°
                    age = np.random.normal(28, 12)
                    income = np.random.normal(30000, 10000)
                    credit_score = np.random.normal(550, 40)
                
                customer = {
                    "customer_id": f"CUST_{i+1:04d}",
                    "age": max(18, int(age)),
                    "income": max(20000, income),
                    "credit_score": max(300, min(850, int(credit_score))),
                    "transaction_count": np.random.poisson(20),
                    "avg_transaction_amount": np.random.exponential(100),
                    "account_balance": np.random.exponential(5000),
                    "loan_amount": np.random.exponential(10000) if np.random.random() > 0.3 else 0,
                    "timestamp": "2025-08-12T00:00:00Z"
                }
                customers.append(customer)
            
            # ë²Œí¬ ì¸ë±ì‹±
            bulk_body = []
            for customer in customers:
                bulk_body.extend([
                    {"index": {"_index": index_name}},
                    customer
                ])
            
            self.client.bulk(body=bulk_body, refresh=True)
            print(f"âœ… {len(customers)}ê°œ ê³ ê° ë°ì´í„° ìƒì„± ì™„ë£Œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def test_kmeans_clustering(self):
        """K-Means í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¯ 3. K-Means í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        try:
            # K-Means ëª¨ë¸ ìƒì„±
            kmeans_config = {
                "name": "customer_segmentation_kmeans",
                "version": "1.0.0",
                "description": "ê³ ê° ì„¸ë¶„í™”ë¥¼ ìœ„í•œ K-Means í´ëŸ¬ìŠ¤í„°ë§",
                "model_format": "TORCH_SCRIPT",
                "model_state": "TRAINED",
                "model_config": {
                    "model_type": "kmeans",
                    "embedding_dimension": 6,
                    "framework_type": "sklearn"
                },
                "created_time": int(time.time() * 1000),
                "last_updated_time": int(time.time() * 1000)
            }
            
            # ML Commons APIë¥¼ í†µí•œ ëª¨ë¸ ë“±ë¡
            try:
                register_response = self.client.transport.perform_request(
                    'POST',
                    '/_plugins/_ml/models/_register',
                    body=kmeans_config
                )
                print("âœ… K-Means ëª¨ë¸ ë“±ë¡ ì„±ê³µ")
                print(f"   ëª¨ë¸ ID: {register_response.get('model_id', 'N/A')}")
                model_id = register_response.get('model_id')
                
            except Exception as e:
                print(f"ğŸ“ ëª¨ë¸ ë“±ë¡ ì‹¤íŒ¨ (ì˜ˆìƒëœ ë™ì‘ì¼ ìˆ˜ ìˆìŒ): {e}")
                print("ğŸ’¡ ëŒ€ì‹  ê²€ìƒ‰ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                model_id = None
            
            # í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ (ì§‘ê³„ ì¿¼ë¦¬ í™œìš©)
            clustering_query = {
                "size": 0,
                "aggs": {
                    "income_ranges": {
                        "range": {
                            "field": "income",
                            "ranges": [
                                {"key": "low", "to": 40000},
                                {"key": "medium", "from": 40000, "to": 80000},
                                {"key": "high", "from": 80000}
                            ]
                        },
                        "aggs": {
                            "avg_credit_score": {"avg": {"field": "credit_score"}},
                            "avg_age": {"avg": {"field": "age"}},
                            "avg_transaction_amount": {"avg": {"field": "avg_transaction_amount"}},
                            "customer_count": {"value_count": {"field": "customer_id"}}
                        }
                    },
                    "credit_score_segments": {
                        "range": {
                            "field": "credit_score",
                            "ranges": [
                                {"key": "poor", "to": 580},
                                {"key": "fair", "from": 580, "to": 670},
                                {"key": "good", "from": 670, "to": 740},
                                {"key": "excellent", "from": 740}
                            ]
                        },
                        "aggs": {
                            "avg_income": {"avg": {"field": "income"}},
                            "avg_loan_amount": {"avg": {"field": "loan_amount"}}
                        }
                    }
                }
            }
            
            result = self.client.search(
                index="ml-customer-data",
                body=clustering_query
            )
            
            print("\nğŸ“Š ì†Œë“ ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™”:")
            for bucket in result['aggregations']['income_ranges']['buckets']:
                print(f"   {bucket['key']} ê·¸ë£¹ ({bucket['doc_count']}ëª…):")
                print(f"     - í‰ê·  ì‹ ìš©ì ìˆ˜: {bucket['avg_credit_score']['value']:.1f}")
                print(f"     - í‰ê·  ë‚˜ì´: {bucket['avg_age']['value']:.1f}ì„¸")
                print(f"     - í‰ê·  ê±°ë˜ê¸ˆì•¡: ${bucket['avg_transaction_amount']['value']:.2f}")
            
            print("\nğŸ“Š ì‹ ìš©ì ìˆ˜ ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™”:")
            for bucket in result['aggregations']['credit_score_segments']['buckets']:
                print(f"   {bucket['key']} ë“±ê¸‰ ({bucket['doc_count']}ëª…):")
                print(f"     - í‰ê·  ì†Œë“: ${bucket['avg_income']['value']:.2f}")
                print(f"     - í‰ê·  ëŒ€ì¶œê¸ˆì•¡: ${bucket['avg_loan_amount']['value']:.2f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ K-Means í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_rcf_anomaly_detection(self):
        """RCF ì´ìƒ íƒì§€ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” 4. RCF (Random Cut Forest) ì´ìƒ íƒì§€ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        try:
            # ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
            anomaly_index = "ml-transaction-anomaly"
            
            if self.client.indices.exists(index=anomaly_index):
                self.client.indices.delete(index=anomaly_index)
            
            anomaly_mapping = {
                "mappings": {
                    "properties": {
                        "timestamp": {"type": "date"},
                        "transaction_amount": {"type": "float"},
                        "customer_id": {"type": "keyword"},
                        "merchant_category": {"type": "keyword"},
                        "is_anomaly": {"type": "boolean"}
                    }
                }
            }
            
            self.client.indices.create(index=anomaly_index, body=anomaly_mapping)
            print(f"âœ… ì´ìƒ íƒì§€ ì¸ë±ìŠ¤ '{anomaly_index}' ìƒì„±")
            
            # ì‹œê³„ì—´ ê±°ë˜ ë°ì´í„° ìƒì„± (ì •ìƒ + ì´ìƒ íŒ¨í„´)
            transactions = []
            np.random.seed(42)
            
            for i in range(300):
                hour = i % 24
                day = i // 24
                
                # ì •ìƒ ê±°ë˜ íŒ¨í„´ (ì‹œê°„ëŒ€ë³„ ë‹¤ë¥¸ ë¶„í¬)
                if 6 <= hour <= 22:  # í™œë™ ì‹œê°„
                    base_amount = np.random.normal(150, 50)
                else:  # ì•¼ê°„ ì‹œê°„
                    base_amount = np.random.normal(50, 20)
                
                # ì´ìƒ ê±°ë˜ ì£¼ì… (5% í™•ë¥ )
                is_anomaly = np.random.random() < 0.05
                if is_anomaly:
                    transaction_amount = np.random.normal(1000, 200)  # ë¹„ì •ìƒì ìœ¼ë¡œ í° ê±°ë˜
                else:
                    transaction_amount = max(10, base_amount)
                
                transaction = {
                    "timestamp": f"2025-08-{12 + day:02d}T{hour:02d}:00:00Z",
                    "transaction_amount": transaction_amount,
                    "customer_id": f"CUST_{np.random.randint(1, 201):04d}",
                    "merchant_category": np.random.choice(["grocery", "restaurant", "gas", "retail", "online"]),
                    "is_anomaly": is_anomaly
                }
                transactions.append(transaction)
            
            # ë²Œí¬ ì¸ë±ì‹±
            bulk_body = []
            for transaction in transactions:
                bulk_body.extend([
                    {"index": {"_index": anomaly_index}},
                    transaction
                ])
            
            self.client.bulk(body=bulk_body, refresh=True)
            print(f"âœ… {len(transactions)}ê°œ ê±°ë˜ ë°ì´í„° ìƒì„± ì™„ë£Œ")
            
            # RCF ê¸°ë°˜ ì´ìƒ íƒì§€ ì¿¼ë¦¬
            anomaly_query = {
                "size": 0,
                "aggs": {
                    "transaction_stats": {
                        "stats": {"field": "transaction_amount"}
                    },
                    "hourly_pattern": {
                        "date_histogram": {
                            "field": "timestamp",
                            "calendar_interval": "1h"
                        },
                        "aggs": {
                            "avg_amount": {"avg": {"field": "transaction_amount"}},
                            "max_amount": {"max": {"field": "transaction_amount"}},
                            "transaction_count": {"value_count": {"field": "transaction_amount"}}
                        }
                    },
                    "potential_anomalies": {
                        "range": {
                            "field": "transaction_amount",
                            "ranges": [
                                {"key": "normal", "to": 500},
                                {"key": "suspicious", "from": 500, "to": 800},
                                {"key": "anomaly", "from": 800}
                            ]
                        }
                    }
                }
            }
            
            result = self.client.search(index=anomaly_index, body=anomaly_query)
            
            print("\nğŸ“Š ê±°ë˜ ê¸ˆì•¡ í†µê³„:")
            stats = result['aggregations']['transaction_stats']
            print(f"   í‰ê· : ${stats['avg']:.2f}")
            print(f"   ìµœì†Œ: ${stats['min']:.2f}")
            print(f"   ìµœëŒ€: ${stats['max']:.2f}")
            print(f"   í‘œì¤€í¸ì°¨: ${(stats['sum_of_squares']/stats['count'] - (stats['avg'])**2)**0.5:.2f}")
            
            print("\nğŸš¨ ì´ìƒ ê±°ë˜ íƒì§€ ê²°ê³¼:")
            for bucket in result['aggregations']['potential_anomalies']['buckets']:
                if bucket['doc_count'] > 0:
                    print(f"   {bucket['key']} ê±°ë˜: {bucket['doc_count']}ê±´")
            
            # ì‹¤ì œ ì´ìƒ ê±°ë˜ ê²€ìƒ‰
            actual_anomalies_query = {
                "query": {"term": {"is_anomaly": True}},
                "size": 5,
                "sort": [{"transaction_amount": {"order": "desc"}}]
            }
            
            actual_result = self.client.search(index=anomaly_index, body=actual_anomalies_query)
            print(f"\nâœ… ì‹¤ì œ ì£¼ì…ëœ ì´ìƒ ê±°ë˜: {actual_result['hits']['total']['value']}ê±´")
            
            if actual_result['hits']['hits']:
                print("   ìƒìœ„ ì´ìƒ ê±°ë˜:")
                for hit in actual_result['hits']['hits'][:3]:
                    source = hit['_source']
                    print(f"     - ${source['transaction_amount']:.2f} ({source['timestamp']}) - {source['merchant_category']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ RCF ì´ìƒ íƒì§€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_model_management(self):
        """ëª¨ë¸ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ› ï¸ 5. ML ëª¨ë¸ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("-" * 30)
        
        try:
            # ë“±ë¡ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
            try:
                models_response = self.client.transport.perform_request(
                    'GET',
                    '/_plugins/_ml/models/_search',
                    body={
                        "query": {"match_all": {}},
                        "size": 10
                    }
                )
                
                print("ğŸ“‹ ë“±ë¡ëœ ML ëª¨ë¸:")
                if models_response.get('hits', {}).get('hits'):
                    for model in models_response['hits']['hits']:
                        model_info = model['_source']
                        print(f"   - ID: {model['_id']}")
                        print(f"     ì´ë¦„: {model_info.get('name', 'N/A')}")
                        print(f"     ìƒíƒœ: {model_info.get('model_state', 'N/A')}")
                        print(f"     íƒ€ì…: {model_info.get('model_config', {}).get('model_type', 'N/A')}")
                else:
                    print("   ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"ğŸ“ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # ML í†µê³„ ì •ë³´ ì¡°íšŒ
            try:
                stats_response = self.client.transport.perform_request(
                    'GET',
                    '/_plugins/_ml/stats'
                )
                
                print("\nğŸ“Š ML Commons í†µê³„:")
                if 'nodes' in stats_response:
                    for node_id, node_stats in stats_response['nodes'].items():
                        print(f"   ë…¸ë“œ {node_id}:")
                        ml_stats = node_stats.get('plugins', {}).get('ml_commons', {})
                        if ml_stats:
                            print(f"     - ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…: {ml_stats.get('ml_executing_task_count', 0)}")
                            print(f"     - ë“±ë¡ëœ ëª¨ë¸: {ml_stats.get('ml_model_count', 0)}")
                        else:
                            print("     - ML Commons í†µê³„ ì •ë³´ ì—†ìŒ")
                            
            except Exception as e:
                print(f"ğŸ“ ML í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # ML ì‘ì—… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
            print("\nğŸ”„ ê°„ë‹¨í•œ ML ì‘ì—… ì‹¤í–‰ í…ŒìŠ¤íŠ¸:")
            
            # ì˜ˆì¸¡ ëª¨ë¸ë§ì„ ìœ„í•œ ì§‘ê³„ ì¿¼ë¦¬
            prediction_query = {
                "size": 0,
                "aggs": {
                    "credit_risk_prediction": {
                        "terms": {
                            "script": {
                                "source": """
                                    double score = doc['credit_score'].value;
                                    double income = doc['income'].value;
                                    double loan = doc['loan_amount'].value;
                                    
                                    if (score > 700 && income > 60000) return 'low_risk';
                                    else if (score < 600 || loan > income * 0.5) return 'high_risk';
                                    else return 'medium_risk';
                                """
                            }
                        },
                        "aggs": {
                            "avg_credit_score": {"avg": {"field": "credit_score"}},
                            "avg_income": {"avg": {"field": "income"}},
                            "default_probability": {
                                "bucket_script": {
                                    "buckets_path": {
                                        "credit_score": "avg_credit_score"
                                    },
                                    "script": "Math.max(0, (700 - params.credit_score) / 400.0)"
                                }
                            }
                        }
                    }
                }
            }
            
            result = self.client.search(index="ml-customer-data", body=prediction_query)
            
            print("   ì‹ ìš© ìœ„í—˜ ì˜ˆì¸¡ ê²°ê³¼:")
            for bucket in result['aggregations']['credit_risk_prediction']['buckets']:
                risk_level = bucket['key']
                count = bucket['doc_count']
                avg_score = bucket['avg_credit_score']['value']
                default_prob = bucket['default_probability']['value']
                
                print(f"     {risk_level}: {count}ëª…")
                print(f"       - í‰ê·  ì‹ ìš©ì ìˆ˜: {avg_score:.1f}")
                print(f"       - ì˜ˆìƒ ë¶€ë„í™•ë¥ : {default_prob:.2%}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_ml_insights(self):
        """ML ì¸ì‚¬ì´íŠ¸ ë° í™œìš© ì‚¬ë¡€ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ’¡ 6. ML ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë¶„ì„")
        print("-" * 30)
        
        try:
            # ë³µí•© ML ë¶„ì„ ì¿¼ë¦¬
            insights_query = {
                "size": 0,
                "aggs": {
                    "customer_value_analysis": {
                        "composite": {
                            "sources": [
                                {"income_tier": {"terms": {"field": "income", "script": {
                                    "source": "Math.floor(doc['income'].value / 25000) * 25000"
                                }}}},
                                {"age_group": {"terms": {"field": "age", "script": {
                                    "source": "doc['age'].value < 30 ? 'young' : doc['age'].value < 50 ? 'middle' : 'senior'"
                                }}}}
                            ]
                        },
                        "aggs": {
                            "customer_count": {"value_count": {"field": "customer_id"}},
                            "avg_credit_score": {"avg": {"field": "credit_score"}},
                            "total_loan_exposure": {"sum": {"field": "loan_amount"}},
                            "avg_transaction_frequency": {"avg": {"field": "transaction_count"}},
                            "customer_lifetime_value": {
                                "bucket_script": {
                                    "buckets_path": {
                                        "avg_transaction": "avg_transaction_frequency",
                                        "avg_amount": "_count"
                                    },
                                    "script": "params.avg_transaction * 12 * 100"  # ì—°ê°„ ì˜ˆìƒ ìˆ˜ìµ
                                }
                            }
                        }
                    },
                    "risk_profiling": {
                        "range": {
                            "field": "credit_score",
                            "ranges": [
                                {"key": "high_risk", "to": 600},
                                {"key": "medium_risk", "from": 600, "to": 700},
                                {"key": "low_risk", "from": 700}
                            ]
                        },
                        "aggs": {
                            "total_exposure": {"sum": {"field": "loan_amount"}},
                            "avg_income": {"avg": {"field": "income"}},
                            "portfolio_percentage": {
                                "bucket_script": {
                                    "buckets_path": {"count": "_count"},
                                    "script": "params.count"
                                }
                            }
                        }
                    }
                }
            }
            
            result = self.client.search(index="ml-customer-data", body=insights_query)
            
            print("ğŸ“Š ê³ ê° ê°€ì¹˜ ë¶„ì„ (ì†Œë“êµ¬ê°„ Ã— ì—°ë ¹ëŒ€):")
            total_customers = 0
            for bucket in result['aggregations']['customer_value_analysis']['buckets']:
                income_tier = bucket['key']['income_tier']
                age_group = bucket['key']['age_group']
                count = bucket['customer_count']['value']
                clv = bucket['customer_lifetime_value']['value']
                total_customers += count
                
                print(f"   ${income_tier:,.0f}+ {age_group} ê·¸ë£¹: {count:.0f}ëª…")
                print(f"     - ì˜ˆìƒ ê³ ê°ìƒì• ê°€ì¹˜: ${clv:,.0f}")
                print(f"     - í‰ê·  ì‹ ìš©ì ìˆ˜: {bucket['avg_credit_score']['value']:.1f}")
            
            print(f"\nğŸ“Š ìœ„í—˜ë„ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„:")
            total_exposure = 0
            for bucket in result['aggregations']['risk_profiling']['buckets']:
                risk_level = bucket['key']
                count = bucket['doc_count']
                exposure = bucket['total_exposure']['value']
                total_exposure += exposure
                
                print(f"   {risk_level}: {count}ëª… (${exposure:,.0f} ë…¸ì¶œ)")
                print(f"     - í‰ê·  ì†Œë“: ${bucket['avg_income']['value']:,.0f}")
            
            # ML ê¸°ë°˜ ì¶”ì²œ ì „ëµ
            print(f"\nğŸ¯ ML ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì¶”ì²œ:")
            print(f"   ğŸ’° ì´ ëŒ€ì¶œ ë…¸ì¶œ: ${total_exposure:,.0f}")
            print(f"   ğŸ‘¥ ì´ ê³ ê° ìˆ˜: {total_customers:.0f}ëª…")
            print(f"   ğŸ“ˆ ì¶”ì²œ ì „ëµ:")
            print(f"     1. ê³ ì†Œë“ ì¤‘ë…„ì¸µ íƒ€ê²Ÿ ë§ˆì¼€íŒ… ê°•í™”")
            print(f"     2. ì €ìœ„í—˜ ê³ ê° ëŒ€ìƒ ëŒ€ì¶œ ìƒí’ˆ í™•ëŒ€")
            print(f"     3. ê³ ìœ„í—˜ ê³ ê° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•")
            print(f"     4. ì—°ë ¹ë³„ ë§ì¶¤í˜• ê¸ˆìœµìƒí’ˆ ê°œë°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ML ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  ML Commons í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ OpenSearch ML Commons í”ŒëŸ¬ê·¸ì¸ ì¢…í•© í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        test_results = {}
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_methods = [
            ("í”ŒëŸ¬ê·¸ì¸ ìƒíƒœ í™•ì¸", self.check_ml_plugin_status),
            ("ìƒ˜í”Œ ë°ì´í„° ìƒì„±", self.setup_sample_data),
            ("K-Means í´ëŸ¬ìŠ¤í„°ë§", self.test_kmeans_clustering),
            ("RCF ì´ìƒ íƒì§€", self.test_rcf_anomaly_detection),
            ("ëª¨ë¸ ê´€ë¦¬", self.test_model_management),
            ("ML ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸", self.test_ml_insights)
        ]
        
        for test_name, test_method in test_methods:
            try:
                result = test_method()
                test_results[test_name] = result
                if result:
                    print(f"\nâœ… {test_name} í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                else:
                    print(f"\nâŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            except Exception as e:
                print(f"\nğŸ’¥ {test_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
                test_results[test_name] = False
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\n" + "=" * 60)
        print("ğŸ“‹ ML Commons í”ŒëŸ¬ê·¸ì¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        passed_tests = sum(1 for result in test_results.values() if result)
        total_tests = len(test_results)
        
        for test_name, result in test_results.items():
            status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
            print(f"   {test_name}: {status}")
        
        print(f"\nğŸ¯ ì„±ê³µë¥ : {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
        
        if passed_tests == total_tests:
            print("ğŸ‰ ëª¨ë“  ML Commons í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # í™œìš© ê°€ì´ë“œ
        print(f"\n" + "=" * 60)
        print("ğŸ’¡ ML Commons í™œìš© ê°€ì´ë“œ (KCB ë§ì¶¤)")
        print("=" * 60)
        print("ğŸ¯ ê¸ˆìœµì—… ML í™œìš© ì‚¬ë¡€:")
        print("   1. ê³ ê° ì„¸ë¶„í™” (Customer Segmentation)")
        print("      - K-Meansë¡œ ê³ ê° ê·¸ë£¹ ë¶„ì„")
        print("      - ë§ì¶¤í˜• ìƒí’ˆ ì¶”ì²œ")
        print("      - ë§ˆì¼€íŒ… íƒ€ê²ŸíŒ… ìµœì í™”")
        print()
        print("   2. ì‹ ìš© ìœ„í—˜ ê´€ë¦¬ (Credit Risk Management)")
        print("      - ì‹ ìš©ì ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸")
        print("      - ë¶€ë„ í™•ë¥  ê³„ì‚°")
        print("      - í¬íŠ¸í´ë¦¬ì˜¤ ìœ„í—˜ ë¶„ì„")
        print()
        print("   3. ì´ìƒ ê±°ë˜ íƒì§€ (Fraud Detection)")
        print("      - RCF ê¸°ë°˜ ì‹¤ì‹œê°„ ì´ìƒ íƒì§€")
        print("      - ê±°ë˜ íŒ¨í„´ ëª¨ë‹ˆí„°ë§")
        print("      - ìë™í™”ëœ ì•Œë¦¼ ì‹œìŠ¤í…œ")
        print()
        print("   4. ê°œì¸í™” ì„œë¹„ìŠ¤")
        print("      - ê³ ê° í–‰ë™ ì˜ˆì¸¡")
        print("      - ìƒí’ˆ ì¶”ì²œ ì—”ì§„")
        print("      - ê³ ê° ìƒì• ê°€ì¹˜ ë¶„ì„")
        print()
        print("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:")
        print("   1. Anomaly Detection í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ êµ¬ì¶•")
        print("   2. Alerting í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™")
        print("   3. ì‹¤ì œ ì—…ë¬´ ë°ì´í„°ë¡œ í”„ë¡œí† íƒ€ì… ê°œë°œ")
        print("   4. ML íŒŒì´í”„ë¼ì¸ ìë™í™” êµ¬ì¶•")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = MLCommonsPluginTester()
    tester.run_all_tests()


if __name__ == "__main__":
    main()